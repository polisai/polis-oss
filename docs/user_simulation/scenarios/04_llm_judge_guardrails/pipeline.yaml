id: llm-judge-guardrails
version: 1
agentId: "*"
protocol: http
nodes:
  - id: start
    type: llm_judge
    config:
      provider: "openai"
      model: "gpt-4o-mini"
      api_key_env: "JUDGE_API_KEY"
      prompt_template: "safety_check" # Matches filename in prompts/tasks/
    on:
      success: egress
      failure: deny

  - id: egress
    type: egress
    config:
      upstream_url: "http://localhost:8081"
      upstream_mode: static
    on:
      success: ""

  - id: deny
    type: terminal.deny
