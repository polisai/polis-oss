server:
  listenParams:
    - address: ":8090"
      protocol: "http"

pipelines:
  - id: llm-judge-guardrails
    version: 1
    agentId: "*"
    protocol: http
    triggers:
      - type: http.request
        match:
          path: "/v1/chat/completions"
    nodes:
      - id: start
        type: llm.judge
        config:
          provider: "openai"
          model: "gpt-4o-mini"
          taskId: "safety_check"
          rulesId: "strict_safety"
          target: "request.body"
          mode: "strict"
        on:
          success: egress
          failure: deny

      - id: egress
        type: egress.http
        config:
          upstream_url: "http://localhost:8081"
          upstream_mode: static
        on:
          success: ""

      - id: deny
        type: terminal.deny
